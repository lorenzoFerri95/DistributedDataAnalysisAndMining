{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# librerie\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.ml.clustering import BisectingKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessione\n",
    "\n",
    "sc = SparkContext(appName=\"DDAM_Project\", master=\"local[*]\")\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"DDAM_Project\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Current_Loan_Amount: integer (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Credit_Score: integer (nullable = true)\n",
      " |-- Annual_Income: integer (nullable = true)\n",
      " |-- Years_in_current_job: string (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Open_Accounts: integer (nullable = true)\n",
      " |-- Number_of_Credit_Problems: integer (nullable = true)\n",
      " |-- Current_Credit_Balance: integer (nullable = true)\n",
      " |-- Maximum_Open_Credit: integer (nullable = true)\n",
      " |-- Bankruptcies: string (nullable = true)\n",
      " |-- Tax_Liens: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.csv(\"hdfs://kddrtserver11.isti.cnr.it:9000/user/hpsa04/credit_train.csv\", sep=\",\",\n",
    "                     inferSchema=True, header=True)\n",
    "\n",
    "columns = sdf.schema.names\n",
    "\n",
    "# rinominare le colonne sotituendo lo spazio con l'underscore\n",
    "for col in columns:\n",
    "    sdf = sdf.withColumnRenamed(col, col.replace(' ', '_'))\n",
    "\n",
    "columns = sdf.schema.names\n",
    "\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_nbr_nulls(spark_df, view_name, print_result = True):\n",
    "    \"\"\"funzione per ottenere il numero di valori nulli presenti in ogni attributo\"\"\"\n",
    "    \n",
    "    spark_df.createOrReplaceTempView(view_name)\n",
    "    \n",
    "    columns_temp = spark_df.schema.names\n",
    "    \n",
    "    Project = []\n",
    "    for col in columns_temp:\n",
    "        Project.append('SUM(CASE WHEN {0} IS NULL THEN 1 ELSE 0 END) AS {0}'.format(col))\n",
    "    Project = ', '.join(Project)\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    SELECT {0}\n",
    "    FROM {1}\\\n",
    "    \"\"\".format(Project, view_name)\n",
    "    \n",
    "    nbr_nulls = spark.sql(sql).first().asDict()\n",
    "    \n",
    "    if print_result:\n",
    "        for key, value in nbr_nulls.items():\n",
    "            print(key + ':', '{:>10}'.format(value))\n",
    "        \n",
    "    return nbr_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID:        514\n",
      "Customer_ID:        514\n",
      "Loan_Status:        514\n",
      "Current_Loan_Amount:        514\n",
      "Term:        514\n",
      "Credit_Score:      19668\n",
      "Annual_Income:      19668\n",
      "Years_in_current_job:        514\n",
      "Home_Ownership:        514\n",
      "Purpose:        514\n",
      "Monthly_Debt:        514\n",
      "Years_of_Credit_History:        514\n",
      "Months_since_last_delinquent:        514\n",
      "Number_of_Open_Accounts:        514\n",
      "Number_of_Credit_Problems:        514\n",
      "Current_Credit_Balance:        514\n",
      "Maximum_Open_Credit:        516\n",
      "Bankruptcies:        514\n",
      "Tax_Liens:        514\n"
     ]
    }
   ],
   "source": [
    "nbr_nulls = get_nbr_nulls(spark_df = sdf, view_name = 'Bank_Loan_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nbr_distincts(spark_df, view_name, print_result = True):\n",
    "    \"\"\"funzione per ottenere il numero di valori distinti di ciascun attributo.\n",
    "    il valore nullo non viene contato come valore distinto\"\"\"\n",
    "    \n",
    "    spark_df.createOrReplaceTempView(view_name)\n",
    "    \n",
    "    columns_temp = spark_df.schema.names\n",
    "\n",
    "    Project = []\n",
    "    for col in columns_temp:\n",
    "        Project.append('COUNT(DISTINCT {0}) AS {0}'.format(col))\n",
    "    Project = ', '.join(Project)\n",
    "\n",
    "    sql = \"\"\"\\\n",
    "    SELECT {0}\n",
    "    FROM {1}\\\n",
    "    \"\"\".format(Project, view_name)\n",
    "    \n",
    "    nbr_distincts = spark.sql(sql).first().asDict()\n",
    "    \n",
    "    if print_result:\n",
    "        for key, value in nbr_distincts.items():\n",
    "            print(key + ':', '{:>10}'.format(value))\n",
    "\n",
    "    return nbr_distincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_ID:      81999\n",
      "Customer_ID:      81999\n",
      "Loan_Status:          2\n",
      "Current_Loan_Amount:      22004\n",
      "Term:          2\n",
      "Credit_Score:        324\n",
      "Annual_Income:      36174\n",
      "Years_in_current_job:         12\n",
      "Home_Ownership:          4\n",
      "Purpose:         16\n",
      "Monthly_Debt:      65765\n",
      "Years_of_Credit_History:        506\n",
      "Months_since_last_delinquent:        117\n",
      "Number_of_Open_Accounts:         51\n",
      "Number_of_Credit_Problems:         14\n",
      "Current_Credit_Balance:      32730\n",
      "Maximum_Open_Credit:      44596\n",
      "Bankruptcies:          9\n",
      "Tax_Liens:         13\n"
     ]
    }
   ],
   "source": [
    "nbr_distincts = get_nbr_distincts(spark_df = sdf, view_name = 'Bank_Loan_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modifiche agli attributi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'le Row sono tipi particolari di Tuple, quindi sono oggetti immutabili.\\nin tutto il notebook allora per modificare gli RDD li trasformiamo temporaneamente (dentro le funzioni)\\nin RDD di Dictionaries.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sdf.rdd  # di default questa trasformazione genera un RDD di Row()\n",
    "\n",
    "'''le Row sono tipi particolari di Tuple, quindi sono oggetti immutabili.\n",
    "in tutto il notebook allora per modificare gli RDD li trasformiamo temporaneamente (dentro le funzioni)\n",
    "in RDD di Dictionaries.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gli attributi che riguardano somme di denaro sono quantità denominate in valuta russa (Rubli). Il dataset si riferisce a dati del 2016, quindi per rendere più comprensibile il significato di queste somme tutti questi attributi vengono convertiti in Euro dividendo tutti i loro valori per il tasso di cambio EUR/RUB medio arrotondato alle decine dell'anno 2016: 70.\n",
    "\n",
    "questa modifica non impatta assolutamente nessuna analisi perché tutte le quantità monetarie vengono trasformate alla stessa maniera e quindi le proporzioni vengono mantenute. Sarà sempre possibile trasformare facilmente di nuovo in Rubli qualora sia necessario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    d = row.asDict()\n",
    "    \n",
    "    if d['Current_Loan_Amount'] is not None:\n",
    "        d['Current_Loan_Amount'] = int(d['Current_Loan_Amount']/70)\n",
    "    \n",
    "    if d['Annual_Income'] is not None:    \n",
    "        d['Annual_Income'] = int(d['Annual_Income']/70)\n",
    "    \n",
    "    if d['Monthly_Debt'] is not None:\n",
    "        d['Monthly_Debt'] = d['Monthly_Debt']/70\n",
    "        \n",
    "    if d['Current_Credit_Balance'] is not None:\n",
    "        d['Current_Credit_Balance'] = int(d['Current_Credit_Balance']/70)\n",
    "        \n",
    "    if d['Maximum_Open_Credit'] is not None:\n",
    "        d['Maximum_Open_Credit'] = int(d['Maximum_Open_Credit']/70)\n",
    "    \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ci sono alcuni attributi che hanno un Data Type incoerente con il significato dell'attributo: sono letti come stringhe ma in realtà la loro semantica ci suggerisce di trasformarli in numerici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|Years_in_current_job|count|\n",
      "+--------------------+-----+\n",
      "|           10+ years|31121|\n",
      "|             2 years| 9134|\n",
      "|             3 years| 8169|\n",
      "|            < 1 year| 8164|\n",
      "|             5 years| 6787|\n",
      "|              1 year| 6460|\n",
      "|             4 years| 6143|\n",
      "|             6 years| 5686|\n",
      "|             7 years| 5577|\n",
      "|             8 years| 4582|\n",
      "|                 n/a| 4222|\n",
      "|             9 years| 3955|\n",
      "|                null|  514|\n",
      "+--------------------+-----+\n",
      "\n",
      "+----------------------------+-----+\n",
      "|Months_since_last_delinquent|count|\n",
      "+----------------------------+-----+\n",
      "|                          NA|53141|\n",
      "|                          13|  922|\n",
      "|                          12|  902|\n",
      "|                          14|  877|\n",
      "|                          15|  865|\n",
      "|                          10|  861|\n",
      "|                           8|  856|\n",
      "|                           9|  849|\n",
      "|                          18|  847|\n",
      "|                          16|  837|\n",
      "|                           6|  836|\n",
      "|                           7|  825|\n",
      "|                          21|  812|\n",
      "|                          17|  809|\n",
      "|                          19|  791|\n",
      "|                          11|  779|\n",
      "|                          22|  775|\n",
      "|                          23|  773|\n",
      "|                          20|  750|\n",
      "|                          28|  746|\n",
      "|                          25|  738|\n",
      "|                          30|  726|\n",
      "|                          27|  723|\n",
      "|                          26|  723|\n",
      "|                          24|  715|\n",
      "|                           5|  703|\n",
      "|                          38|  697|\n",
      "|                          31|  697|\n",
      "|                          29|  686|\n",
      "|                          33|  679|\n",
      "|                          40|  672|\n",
      "|                          32|  668|\n",
      "|                          34|  648|\n",
      "|                          36|  644|\n",
      "|                          39|  637|\n",
      "|                          41|  624|\n",
      "|                          44|  623|\n",
      "|                          45|  621|\n",
      "|                          35|  616|\n",
      "|                          42|  611|\n",
      "|                          43|  605|\n",
      "|                          37|  592|\n",
      "|                          48|  583|\n",
      "|                          47|  572|\n",
      "|                          46|  566|\n",
      "|                        null|  514|\n",
      "|                          49|  514|\n",
      "|                           4|  513|\n",
      "|                           3|  445|\n",
      "|                          53|  444|\n",
      "|                          61|  444|\n",
      "|                          51|  437|\n",
      "|                          59|  427|\n",
      "|                          54|  419|\n",
      "|                           2|  418|\n",
      "|                          60|  417|\n",
      "|                          68|  415|\n",
      "|                          57|  414|\n",
      "|                          63|  406|\n",
      "|                          58|  405|\n",
      "|                          52|  403|\n",
      "|                          55|  402|\n",
      "|                          69|  401|\n",
      "|                          50|  400|\n",
      "|                          56|  391|\n",
      "|                          65|  389|\n",
      "|                          62|  389|\n",
      "|                          64|  388|\n",
      "|                          66|  381|\n",
      "|                          73|  378|\n",
      "|                          71|  377|\n",
      "|                          67|  365|\n",
      "|                          72|  363|\n",
      "|                          74|  359|\n",
      "|                          70|  353|\n",
      "|                          75|  343|\n",
      "|                          78|  342|\n",
      "|                          77|  331|\n",
      "|                          76|  318|\n",
      "|                          80|  309|\n",
      "|                          79|  297|\n",
      "|                           1|  289|\n",
      "|                          81|  287|\n",
      "|                           0|  216|\n",
      "|                          82|  110|\n",
      "|                          83|   17|\n",
      "|                          85|   11|\n",
      "|                          84|    6|\n",
      "|                          87|    4|\n",
      "|                          97|    3|\n",
      "|                          92|    2|\n",
      "|                          96|    2|\n",
      "|                         176|    2|\n",
      "|                         108|    2|\n",
      "|                         120|    2|\n",
      "|                          94|    2|\n",
      "|                          89|    2|\n",
      "|                          86|    2|\n",
      "|                          88|    2|\n",
      "|                          91|    2|\n",
      "|                         139|    1|\n",
      "|                         131|    1|\n",
      "|                         110|    1|\n",
      "|                         115|    1|\n",
      "|                         100|    1|\n",
      "|                         107|    1|\n",
      "|                          93|    1|\n",
      "|                         114|    1|\n",
      "|                         106|    1|\n",
      "|                         130|    1|\n",
      "|                          90|    1|\n",
      "|                         129|    1|\n",
      "|                         148|    1|\n",
      "|                         143|    1|\n",
      "|                         152|    1|\n",
      "|                         118|    1|\n",
      "|                         104|    1|\n",
      "|                         141|    1|\n",
      "+----------------------------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|Bankruptcies|count|\n",
      "+------------+-----+\n",
      "|           0|88774|\n",
      "|           1|10475|\n",
      "|        null|  514|\n",
      "|           2|  417|\n",
      "|          NA|  204|\n",
      "|           3|   93|\n",
      "|           4|   27|\n",
      "|           5|    7|\n",
      "|           6|    2|\n",
      "|           7|    1|\n",
      "+------------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|Tax_Liens|count|\n",
      "+---------+-----+\n",
      "|        0|98062|\n",
      "|        1| 1343|\n",
      "|     null|  514|\n",
      "|        2|  374|\n",
      "|        3|  111|\n",
      "|        4|   58|\n",
      "|        5|   16|\n",
      "|        6|   12|\n",
      "|       NA|   10|\n",
      "|        7|    7|\n",
      "|        9|    3|\n",
      "|       11|    2|\n",
      "|       15|    1|\n",
      "|       10|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check dei valori distinti degli attributi con data type incoerente\n",
    "\n",
    "problematic_columns = ['Years_in_current_job', 'Months_since_last_delinquent', 'Bankruptcies', 'Tax_Liens']\n",
    "\n",
    "for col in problematic_columns:\n",
    "    sdf.select(col).groupBy(col).count().orderBy('count', ascending=False).show(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Years_in_current_job'\n",
    "\n",
    "rendiamo numerico quest'attributo in questo modo:\n",
    "\n",
    "years viene tolto da ogni valore.\n",
    "\n",
    "sono presenti 4222 valori uguali a 'n/a'. Pensiamo si possa trattare di soggetti per cui non si può dire qunati anni hanno lavorato nel lavoro corrente perché sono attualmente senza occupazione. Il valore viene quindi sostituito con 0.\n",
    "\n",
    "10+ viene trasformato in 10 perché 10+ non ha valenza semantica non conoscendo la distribuzione dei valori specifici per questa categoria. Questa trasformazione non comporta problematiche per algoritmi di machine learning come il Decision Tree perché l'ordinamento dei valori numerici è preservato (basterà tenere presente che un eventuale split sul valore 10 sarebbe in realtà riferito a valori anche maggiori di 10). L'unica problematica apparente potrebbe manifestarsi per algoritmi basati sulle distanze (es. Clustering, PCA, KNN ecc...) perché la distanza dal valore 10 potrebbe in realtà essere una distanza molto maggiore. Ma non ci preoccupiamo di questo perché le ennuple coinvolte sono relativamente poche e l'errore non avrebbe un impatto rilevante sul calcolo della distanza multidimensionale. E anche soprattutto perché arrivati a 10 anni di lavoro in una posizione si ritiene che il fattore lavorativo non sia ormai più un problema e quindi un'ipotetica \"distanza\" ad esempio tra 10 e 25 anni è tutto sommato meno rilevante di una distanza, anche minore, ma ad esempio tra 10 e 1.\n",
    "\n",
    "< 1 viene trasformato nella media dei valori tra 0 e 1, cioè 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    d = row.asDict()\n",
    "    \n",
    "    if d['Years_in_current_job'] is not None:\n",
    "        d['Years_in_current_job'] = str(d['Years_in_current_job']).replace(' years', '')\n",
    "        d['Years_in_current_job'] = str(d['Years_in_current_job']).replace(' year', '')\n",
    "        \n",
    "        if d['Years_in_current_job'] == 'n/a':\n",
    "            d['Years_in_current_job'] = 0\n",
    "        if d['Years_in_current_job'] == '10+':\n",
    "            d['Years_in_current_job'] = 10\n",
    "        if d['Years_in_current_job'] == '< 1':\n",
    "            d['Years_in_current_job'] = 0.5\n",
    "        \n",
    "        d['Years_in_current_job'] = float(d['Years_in_current_job'])\n",
    "    \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def change_value(row):\\n    d = row.asDict()\\n    if d['Years_in_current_job'] is not None:\\n        \\n        if d['Years_in_current_job'] == '10+ years':\\n            d['Years_in_current_job'] = '>= 10 years'\\n\\n        if (d['Years_in_current_job'] == '4 years') or (d['Years_in_current_job'] == '5 years') or (d['Years_in_current_job'] == '6 years') or (d['Years_in_current_job'] == '7 years') or (d['Years_in_current_job'] == '8 years') or (d['Years_in_current_job'] == '9 years'):\\n            d['Years_in_current_job'] = '>= 4 years and < 10 years'\\n            \\n        if (d['Years_in_current_job'] == '< 1 year') or (d['Years_in_current_job'] == '1 year') or (d['Years_in_current_job'] == '2 years') or (d['Years_in_current_job'] == '3 years'):\\n            d['Years_in_current_job'] = '< 4 years'\\n            \\n    return Row(**d)\\n\\nrdd = rdd.map(change_value)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def change_value(row):\n",
    "    d = row.asDict()\n",
    "    if d['Years_in_current_job'] is not None:\n",
    "        \n",
    "        if d['Years_in_current_job'] == '10+ years':\n",
    "            d['Years_in_current_job'] = '>= 10 years'\n",
    "\n",
    "        if (d['Years_in_current_job'] == '4 years') or (d['Years_in_current_job'] == '5 years') or (d['Years_in_current_job'] == '6 years') or (d['Years_in_current_job'] == '7 years') or (d['Years_in_current_job'] == '8 years') or (d['Years_in_current_job'] == '9 years'):\n",
    "            d['Years_in_current_job'] = '>= 4 years and < 10 years'\n",
    "            \n",
    "        if (d['Years_in_current_job'] == '< 1 year') or (d['Years_in_current_job'] == '1 year') or (d['Years_in_current_job'] == '2 years') or (d['Years_in_current_job'] == '3 years'):\n",
    "            d['Years_in_current_job'] = '< 4 years'\n",
    "            \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Months_since_last_delinquent'\n",
    "\n",
    "sono presenti 53141 valori uguali a 'NA' (la maggior parte). la nostra interpretazione di questo valore è che il soggetto in questione non ha mai commesso nessun reato (interpretazione coerente con il fatto che i valori 'NA' sono la maggior parte).\n",
    "\n",
    "il conteggio degli altri valori distinti è basso, decidiamo quindi di rendere l'attributo categorico raccogliendo i valori in questi range:\n",
    "\n",
    "[0, 12); [12, 48); [48, 96); [96, +inf); 'Never committed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    d = row.asDict()\n",
    "    \n",
    "    if d['Months_since_last_delinquent'] is not None:\n",
    "        if d['Months_since_last_delinquent'] == 'NA':\n",
    "            d['Months_since_last_delinquent'] = 'Never committed'\n",
    "        elif int(d['Months_since_last_delinquent']) < 12:\n",
    "            d['Months_since_last_delinquent'] = '[0, 12)'\n",
    "        elif int(d['Months_since_last_delinquent']) < 48:\n",
    "            d['Months_since_last_delinquent'] = '[12, 48)'\n",
    "        elif int(d['Months_since_last_delinquent']) < 96:\n",
    "            d['Months_since_last_delinquent'] = '[48, 96)'\n",
    "        else:\n",
    "            d['Months_since_last_delinquent'] = '[96, +inf)'\n",
    "            \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def change_value(row):\\n    d = row.asDict()\\n    \\n    if d['Months_since_last_delinquent'] is None:\\n        d['Has_Been_Delinquent'] = None\\n    elif d['Months_since_last_delinquent'] == 'NA':\\n        d['Has_Been_Delinquent'] = '0'\\n    else:\\n        d['Has_Been_Delinquent'] = '1'\\n        \\n    del d['Months_since_last_delinquent']\\n    return Row(**d)\\n\\nrdd = rdd.map(change_value)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def change_value(row):\n",
    "    d = row.asDict()\n",
    "    \n",
    "    if d['Months_since_last_delinquent'] is None:\n",
    "        d['Has_Been_Delinquent'] = None\n",
    "    elif d['Months_since_last_delinquent'] == 'NA':\n",
    "        d['Has_Been_Delinquent'] = '0'\n",
    "    else:\n",
    "        d['Has_Been_Delinquent'] = '1'\n",
    "        \n",
    "    del d['Months_since_last_delinquent']\n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Bankruptcies'\n",
    "\n",
    "l'attributo viene letto come stringa perché sono presenti 204 valori uguali a 'NA'. Poichè il valore 0 è presente si pensa possa trattarsi di missing values, li trasformiamo quindi in None e rendiamo numerico l'attributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    d = row.asDict()\n",
    "    \n",
    "    if d['Bankruptcies'] is not None:\n",
    "        if d['Bankruptcies'] == 'NA':\n",
    "            d['Bankruptcies'] = None\n",
    "        else:\n",
    "            d['Bankruptcies'] = int(d['Bankruptcies'])\n",
    "        \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Tax_Liens'\n",
    "\n",
    "l'attributo viene letto come stringa perché sono presenti 10 valori uguali a 'NA'. Poichè il valore 0 è presente si pensa possa trattarsi di missing values, li trasformiamo quindi in None e rendiamo numerico l'attributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    d = row.asDict()\n",
    "\n",
    "    if d['Tax_Liens'] is not None:\n",
    "        if d['Tax_Liens'] == 'NA':\n",
    "            d['Tax_Liens'] = None\n",
    "        else:\n",
    "            d['Tax_Liens'] = int(d['Tax_Liens'])\n",
    "        \n",
    "    return Row(**d)\n",
    "\n",
    "rdd = rdd.map(change_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Annual_Income: long (nullable = true)\n",
      " |-- Bankruptcies: long (nullable = true)\n",
      " |-- Credit_Score: long (nullable = true)\n",
      " |-- Current_Credit_Balance: long (nullable = true)\n",
      " |-- Current_Loan_Amount: long (nullable = true)\n",
      " |-- Customer_ID: string (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Loan_ID: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Maximum_Open_Credit: long (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Credit_Problems: long (nullable = true)\n",
      " |-- Number_of_Open_Accounts: long (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Tax_Liens: long (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Years_in_current_job: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = rdd.toDF()\n",
    "columns = sdf.schema.names\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|Years_in_current_job|count|\n",
      "+--------------------+-----+\n",
      "|                10.0|31121|\n",
      "|                 2.0| 9134|\n",
      "|                 3.0| 8169|\n",
      "|                 0.5| 8164|\n",
      "|                 5.0| 6787|\n",
      "|                 1.0| 6460|\n",
      "|                 4.0| 6143|\n",
      "|                 6.0| 5686|\n",
      "|                 7.0| 5577|\n",
      "|                 8.0| 4582|\n",
      "|                 0.0| 4222|\n",
      "|                 9.0| 3955|\n",
      "|                null|  514|\n",
      "+--------------------+-----+\n",
      "\n",
      "+----------------------------+-----+\n",
      "|Months_since_last_delinquent|count|\n",
      "+----------------------------+-----+\n",
      "|             Never committed|53141|\n",
      "|                    [12, 48)|25789|\n",
      "|                    [48, 96)|13453|\n",
      "|                     [0, 12)| 7590|\n",
      "|                        null|  514|\n",
      "|                  [96, +inf)|   27|\n",
      "+----------------------------+-----+\n",
      "\n",
      "+------------+-----+\n",
      "|Bankruptcies|count|\n",
      "+------------+-----+\n",
      "|           0|88774|\n",
      "|           1|10475|\n",
      "|        null|  718|\n",
      "|           2|  417|\n",
      "|           3|   93|\n",
      "|           4|   27|\n",
      "|           5|    7|\n",
      "|           6|    2|\n",
      "|           7|    1|\n",
      "+------------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|Tax_Liens|count|\n",
      "+---------+-----+\n",
      "|        0|98062|\n",
      "|        1| 1343|\n",
      "|     null|  524|\n",
      "|        2|  374|\n",
      "|        3|  111|\n",
      "|        4|   58|\n",
      "|        5|   16|\n",
      "|        6|   12|\n",
      "|        7|    7|\n",
      "|        9|    3|\n",
      "|       11|    2|\n",
      "|       10|    1|\n",
      "|       15|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in problematic_columns:\n",
    "    sdf.select(col).groupBy(col).count().orderBy('count', ascending=False).show(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestione degli errori\n",
    "\n",
    "alcuni attributi hanno valori errati o non coerenti con il significato che noi reputiamo possa avere l'attributo. Alcuni di questi errori sono stati scoperti in fasi più avanzate del progetto (ex Data Understanding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Credit_Score'\n",
    "\n",
    "ci sono 4551 valori dell'attributo 'Credit_Score' con valore superiore a 5000, che è un valore troppo distante rispetto a quelli generici che assume questo attributo (da 500 a 800). Controllando i valori distinti si è scoperto che quei valori sono errati: c'è uno '0' di troppo in fondo al numero, che eliminamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4551"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def problematic_values_count(row):\n",
    "    if row['Credit_Score'] is not None:\n",
    "        return row['Credit_Score'] > 5000\n",
    "\n",
    "rdd.filter(problematic_values_count).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|Credit_Score|count|\n",
      "+------------+-----+\n",
      "|        null|19668|\n",
      "|         747| 1825|\n",
      "|         740| 1746|\n",
      "|         746| 1742|\n",
      "|         741| 1732|\n",
      "|         742| 1723|\n",
      "|         739| 1624|\n",
      "|         745| 1612|\n",
      "|         748| 1598|\n",
      "|         743| 1555|\n",
      "|         725| 1548|\n",
      "|         724| 1522|\n",
      "|         738| 1495|\n",
      "|         744| 1485|\n",
      "|         721| 1465|\n",
      "|         723| 1421|\n",
      "|         737| 1405|\n",
      "|         722| 1387|\n",
      "|         718| 1261|\n",
      "|         750| 1234|\n",
      "|         717| 1218|\n",
      "|         720| 1216|\n",
      "|         736| 1156|\n",
      "|         734| 1147|\n",
      "|         735| 1134|\n",
      "|         719| 1118|\n",
      "|         732| 1084|\n",
      "|         733| 1073|\n",
      "|         715| 1070|\n",
      "|         716| 1061|\n",
      "|         714| 1046|\n",
      "|         713| 1017|\n",
      "|         731| 1010|\n",
      "|         712| 1006|\n",
      "|         730|  984|\n",
      "|         728|  931|\n",
      "|         729|  925|\n",
      "|         708|  902|\n",
      "|         709|  865|\n",
      "|         710|  857|\n",
      "|         726|  853|\n",
      "|         749|  827|\n",
      "|         707|  814|\n",
      "|         727|  806|\n",
      "|         711|  791|\n",
      "|         706|  791|\n",
      "|         705|  727|\n",
      "|         751|  723|\n",
      "|         703|  717|\n",
      "|         704|  716|\n",
      "|         699|  660|\n",
      "|         702|  644|\n",
      "|         701|  620|\n",
      "|         700|  612|\n",
      "|         698|  595|\n",
      "|         697|  552|\n",
      "|         693|  509|\n",
      "|         694|  506|\n",
      "|         695|  506|\n",
      "|         692|  504|\n",
      "|         696|  483|\n",
      "|         691|  386|\n",
      "|         689|  384|\n",
      "|         686|  369|\n",
      "|         685|  369|\n",
      "|         687|  367|\n",
      "|         683|  365|\n",
      "|         680|  346|\n",
      "|         688|  338|\n",
      "|         684|  327|\n",
      "|         690|  320|\n",
      "|         678|  298|\n",
      "|         682|  294|\n",
      "|         679|  285|\n",
      "|         676|  284|\n",
      "|         681|  277|\n",
      "|         675|  262|\n",
      "|         674|  262|\n",
      "|         677|  234|\n",
      "|         669|  230|\n",
      "|         668|  227|\n",
      "|         670|  227|\n",
      "|         672|  219|\n",
      "|         673|  212|\n",
      "|         671|  208|\n",
      "|         663|  182|\n",
      "|         667|  176|\n",
      "|         664|  173|\n",
      "|         656|  171|\n",
      "|         661|  168|\n",
      "|         666|  167|\n",
      "|         665|  161|\n",
      "|         659|  148|\n",
      "|         655|  147|\n",
      "|         660|  144|\n",
      "|         662|  137|\n",
      "|         654|  129|\n",
      "|         649|  126|\n",
      "|         657|  123|\n",
      "|         652|  122|\n",
      "|         658|  118|\n",
      "|         653|  118|\n",
      "|        7390|  108|\n",
      "|        7370|  106|\n",
      "|         651|  101|\n",
      "|         645|   99|\n",
      "|         650|   98|\n",
      "|        7400|   97|\n",
      "|        7380|   93|\n",
      "|        7330|   88|\n",
      "|         640|   88|\n",
      "|        7340|   87|\n",
      "|        7410|   87|\n",
      "|         643|   87|\n",
      "|        7360|   85|\n",
      "|        7420|   84|\n",
      "|        7240|   84|\n",
      "|        7320|   83|\n",
      "|         642|   81|\n",
      "|         641|   77|\n",
      "|        7280|   77|\n",
      "|        7460|   76|\n",
      "|        7350|   76|\n",
      "|         648|   76|\n",
      "|        7250|   75|\n",
      "|         646|   75|\n",
      "|        7270|   74|\n",
      "|        7170|   74|\n",
      "|         644|   73|\n",
      "|        7310|   73|\n",
      "|        7300|   73|\n",
      "|         635|   72|\n",
      "|         638|   71|\n",
      "|         647|   71|\n",
      "|        7430|   70|\n",
      "|        7190|   68|\n",
      "|        7160|   68|\n",
      "|         632|   67|\n",
      "|        7260|   64|\n",
      "|        7230|   63|\n",
      "|        7200|   63|\n",
      "|        7140|   62|\n",
      "|         636|   62|\n",
      "|        7290|   60|\n",
      "|        7220|   59|\n",
      "|         633|   58|\n",
      "|        7440|   58|\n",
      "|        7090|   58|\n",
      "|        7180|   57|\n",
      "|        7210|   57|\n",
      "|        7450|   55|\n",
      "|        7100|   54|\n",
      "|        7130|   53|\n",
      "|         624|   52|\n",
      "|        7070|   52|\n",
      "|        7470|   51|\n",
      "|        7120|   51|\n",
      "|         622|   50|\n",
      "|        7080|   50|\n",
      "|        7040|   49|\n",
      "|         637|   47|\n",
      "|        6990|   46|\n",
      "|        7010|   46|\n",
      "|        7060|   45|\n",
      "|        7150|   45|\n",
      "|        7110|   45|\n",
      "|         634|   45|\n",
      "|        7050|   44|\n",
      "|         628|   44|\n",
      "|         627|   43|\n",
      "|        7480|   43|\n",
      "|         639|   42|\n",
      "|         619|   42|\n",
      "|         621|   41|\n",
      "|        6950|   39|\n",
      "|         626|   39|\n",
      "|        7030|   39|\n",
      "|        6960|   38|\n",
      "|        6940|   38|\n",
      "|        7020|   37|\n",
      "|        6930|   36|\n",
      "|        6980|   36|\n",
      "|         625|   36|\n",
      "|        6840|   35|\n",
      "|         630|   35|\n",
      "|        7000|   35|\n",
      "|         616|   34|\n",
      "|         614|   33|\n",
      "|         631|   33|\n",
      "|         618|   32|\n",
      "|        6970|   32|\n",
      "|         612|   32|\n",
      "|         617|   31|\n",
      "|         629|   30|\n",
      "|         615|   30|\n",
      "|        6810|   30|\n",
      "|        6890|   29|\n",
      "|         611|   29|\n",
      "|        6920|   29|\n",
      "|         601|   29|\n",
      "|        6860|   28|\n",
      "|         623|   28|\n",
      "|         610|   28|\n",
      "|        6870|   27|\n",
      "|         609|   26|\n",
      "|         620|   26|\n",
      "|        6900|   25|\n",
      "|        6800|   25|\n",
      "|        6850|   25|\n",
      "|         600|   25|\n",
      "|        6650|   25|\n",
      "|        6830|   24|\n",
      "|        6880|   24|\n",
      "|        7500|   24|\n",
      "|        6740|   24|\n",
      "|         613|   23|\n",
      "|         605|   23|\n",
      "|         597|   23|\n",
      "|        7490|   23|\n",
      "|        6910|   22|\n",
      "|        6750|   22|\n",
      "|        6820|   21|\n",
      "|        6630|   21|\n",
      "|         606|   20|\n",
      "|        6780|   20|\n",
      "|         588|   20|\n",
      "|         608|   19|\n",
      "|         595|   19|\n",
      "|        6660|   19|\n",
      "|         603|   19|\n",
      "|        6790|   18|\n",
      "|        6720|   17|\n",
      "|        6700|   17|\n",
      "|        6670|   17|\n",
      "|        6680|   17|\n",
      "|        6690|   16|\n",
      "|        6730|   16|\n",
      "|         602|   16|\n",
      "|        6770|   16|\n",
      "|         599|   15|\n",
      "|         596|   15|\n",
      "|        6520|   15|\n",
      "|        6710|   14|\n",
      "|        6450|   13|\n",
      "|         604|   13|\n",
      "|        6610|   13|\n",
      "|        6500|   13|\n",
      "|         607|   13|\n",
      "|        6580|   13|\n",
      "|        6620|   13|\n",
      "|        6530|   12|\n",
      "|        6560|   12|\n",
      "|        6590|   12|\n",
      "|        6760|   12|\n",
      "|         585|   12|\n",
      "|        6410|   12|\n",
      "|         587|   11|\n",
      "|        6600|   11|\n",
      "|        6570|   11|\n",
      "|         594|   10|\n",
      "|        6380|    9|\n",
      "|        6640|    9|\n",
      "|        7510|    9|\n",
      "|         591|    9|\n",
      "|         598|    9|\n",
      "|        6510|    9|\n",
      "|        6400|    9|\n",
      "|         590|    8|\n",
      "|        6240|    8|\n",
      "|        6550|    8|\n",
      "|        6540|    7|\n",
      "|        6390|    7|\n",
      "|        6440|    7|\n",
      "|         593|    7|\n",
      "|         586|    7|\n",
      "|        6220|    7|\n",
      "|        6320|    7|\n",
      "|        6490|    7|\n",
      "|        6260|    7|\n",
      "|         589|    6|\n",
      "|        6470|    6|\n",
      "|        6230|    6|\n",
      "|        6480|    6|\n",
      "|        6330|    6|\n",
      "|        6350|    6|\n",
      "|        6300|    6|\n",
      "|        6160|    6|\n",
      "|        6420|    6|\n",
      "|        6180|    5|\n",
      "|        6290|    5|\n",
      "|        6250|    4|\n",
      "|         592|    4|\n",
      "|        6090|    4|\n",
      "|        6340|    4|\n",
      "|        6170|    4|\n",
      "|        6270|    4|\n",
      "|        6360|    4|\n",
      "|        6310|    4|\n",
      "|        6430|    4|\n",
      "|        6110|    4|\n",
      "|        6210|    3|\n",
      "|        6130|    3|\n",
      "|        5950|    3|\n",
      "|        6150|    3|\n",
      "|        5940|    3|\n",
      "|        6460|    3|\n",
      "|        6280|    3|\n",
      "|        6190|    2|\n",
      "|        5850|    2|\n",
      "|        6060|    2|\n",
      "|        6200|    2|\n",
      "|        6080|    2|\n",
      "|        6100|    2|\n",
      "|        6140|    2|\n",
      "|        6120|    2|\n",
      "|        6370|    2|\n",
      "|        5930|    2|\n",
      "|        6070|    1|\n",
      "|        6050|    1|\n",
      "|        6010|    1|\n",
      "|        5860|    1|\n",
      "|        5890|    1|\n",
      "|        5920|    1|\n",
      "|        5960|    1|\n",
      "|        5900|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col = 'Credit_Score'\n",
    "sdf.select(col).groupBy(col).count().orderBy('count', ascending=False).show(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100514"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def errors_correction(row):\n",
    "    d = row.asDict()\n",
    "    if d['Credit_Score'] is not None and d['Credit_Score'] > 5000:\n",
    "        d['Credit_Score'] = int(str(d['Credit_Score'])[:-1])\n",
    "    return Row(**d)\n",
    "    \n",
    "rdd = rdd.map(errors_correction)\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'attributo 'Current_Credit_Balance' non può essere superiore al valore dell'attributo 'Maximum_Open_Credit'\n",
    "\n",
    "# Current_Credit_Balance <= Current_Loan_Amount <= Maximum_Open_Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def errors_correction(row):\\n    if (row['Current_Credit_Balance'] is not None) and (row['Maximum_Open_Credit'] is not None):\\n        return row['Current_Credit_Balance'] <= row['Maximum_Open_Credit']\\n    else:\\n        return row\\n    \\nrdd = rdd.filter(errors_correction)\\nrdd.count()\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def errors_correction(row):\n",
    "    if (row['Current_Credit_Balance'] is not None) and (row['Maximum_Open_Credit'] is not None):\n",
    "        return row['Current_Credit_Balance'] <= row['Maximum_Open_Credit']\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "rdd = rdd.filter(errors_correction)\n",
    "rdd.count()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ci sono diversi valori dell'attributo 'Current_Loan_Amount' che sono pari a 1.428.571 (99.999.999 in Rubli).  un numero eccessivamente più alto rispetto a tutti gli altri valori e che per questo viene eliminato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|Current_Loan_Amount|count|\n",
      "+-------------------+-----+\n",
      "|            1428571|11484|\n",
      "|               null|  514|\n",
      "|               3195|   82|\n",
      "|               3184|   70|\n",
      "|               3088|   66|\n",
      "|               3173|   66|\n",
      "|               3140|   66|\n",
      "|               1556|   65|\n",
      "|               3179|   65|\n",
      "|               1540|   63|\n",
      "|               3069|   62|\n",
      "|               3190|   60|\n",
      "|               1919|   58|\n",
      "|               3080|   58|\n",
      "|               3107|   58|\n",
      "|               1534|   58|\n",
      "|               3157|   58|\n",
      "|               3217|   57|\n",
      "|               3078|   57|\n",
      "|               3206|   56|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col = 'Current_Loan_Amount'\n",
    "sdf.select(col).groupBy(col).count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89030"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def errors_correction(row):\n",
    "    if row['Current_Loan_Amount'] is not None:\n",
    "        return row['Current_Loan_Amount'] != 1428571\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "rdd = rdd.filter(errors_correction)\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mximum open credit di 100 000 000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminiamo le righe dove entrambi gli attributi 'Loan_ID' e 'Customer_ID' sono nulli, che corrispondono alle righe dove tutti i valori di tutti gli attributi sono nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88516"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.filter(lambda row: not ( (row['Loan_ID'] is None) and (row['Customer_ID'] is None) ))\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminiamo le righe duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78301"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.distinct()\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema: ci sono coppie di righe con tutti i valori duplicati eccetto per le due colonne 'Credit_Score' e 'Annual_Income', per le quali uno dei due valori è presente e l'altro è nullo.\n",
    "\n",
    "Soluzione: si raggruppa per tutti gli attributi tranne quei due e poi si calcola la media di quei due. In questo modo se le uniche due righe uguali sono quelle con un valore nullo e uno non nullo per quegli attributi, lo media sarà uguale al valore non nullo; se invece ci fossero altre righe ugauli ma con altri valori diversi non nulli per quegli attributi, viene effettivamente calcolata la media, il che è auspicabile considerando che tutto il resto della riga è uguale e quindi si tratta molto probabilmente dello stesso oggetto, duplicato per errore, di cui dunque prendiamo un valore medio tra quelli presenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = rdd.toDF()\n",
    "\n",
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "columns_temp = [col for col in columns if col != 'Credit_Score' and col != 'Annual_Income']\n",
    "Project = ', '.join(columns_temp)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT {0}, BIGINT(AVG(Credit_Score)) AS Credit_Score, BIGINT(AVG(Annual_Income)) AS Annual_Income\n",
    "FROM Bank_Loan_Dataset\n",
    "GROUP BY {0}\n",
    "\"\"\".format(Project)\n",
    "\n",
    "sdf = spark.sql(sql)\n",
    "\n",
    "del columns_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come si nota i Customer e Loan ID che si ripetevano nel dataset originale erano solo righe duplicate. Il dataset pulito non presenta nessuna riga uguale negli ID e possiamo quindi eliminarli. Anche escludendo questi attributi tutte le righe rimangono distinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+---------+\n",
      "|nbr_rows|nbr_customers|nbr_loans|\n",
      "+--------+-------------+---------+\n",
      "|   74094|        74094|    74094|\n",
      "+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT COUNT(*) AS nbr_rows, COUNT(DISTINCT Customer_ID) AS nbr_customers, COUNT(DISTINCT Loan_ID) AS nbr_loans\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in columns if col != 'Customer_ID' and col != 'Loan_ID']\n",
    "\n",
    "columns_categorical = [col.name for col in sdf.schema.fields if isinstance(col.dataType, StringType)]\n",
    "\n",
    "columns_numerical = [col for col in columns if col not in columns_categorical]\n",
    "\n",
    "sdf = sdf.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Annual_Income: long (nullable = true)\n",
      " |-- Bankruptcies: long (nullable = true)\n",
      " |-- Credit_Score: long (nullable = true)\n",
      " |-- Current_Credit_Balance: long (nullable = true)\n",
      " |-- Current_Loan_Amount: long (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Maximum_Open_Credit: long (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Credit_Problems: long (nullable = true)\n",
      " |-- Number_of_Open_Accounts: long (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Tax_Liens: long (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Years_in_current_job: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gestione dei Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Income:      14947\n",
      "Bankruptcies:        156\n",
      "Credit_Score:      14947\n",
      "Current_Credit_Balance:          0\n",
      "Current_Loan_Amount:          0\n",
      "Home_Ownership:          0\n",
      "Loan_Status:          0\n",
      "Maximum_Open_Credit:          2\n",
      "Monthly_Debt:          0\n",
      "Months_since_last_delinquent:          0\n",
      "Number_of_Credit_Problems:          0\n",
      "Number_of_Open_Accounts:          0\n",
      "Purpose:          0\n",
      "Tax_Liens:          7\n",
      "Term:          0\n",
      "Years_in_current_job:          0\n",
      "Years_of_Credit_History:          0\n"
     ]
    }
   ],
   "source": [
    "nbr_nulls = get_nbr_nulls(spark_df=sdf, view_name = 'Bank_Loan_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filliamo i Missing values degli attributi \"Maximum_Open_Credit\", \"Bankruptcies\" e \"Tax_Liens\" usando la Moda di diversi tipi di raggruppamenti.\n",
    "\n",
    "per farlo usiamo la sintassi dell'SQL analitico, creando nuove apposite colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *,\n",
    "    BIGINT( PERCENTILE(Maximum_Open_Credit, 0.5) OVER(PARTITION BY Years_in_current_job,\n",
    "                                                Home_Ownership,\n",
    "                                                Number_of_Open_Accounts,\n",
    "                                                Years_of_Credit_History) ) AS toFill_Maximum_Open_Credit,\n",
    "    BIGINT( PERCENTILE(Bankruptcies, 0.5) OVER(PARTITION BY Months_since_last_delinquent,\n",
    "                                                Number_of_Credit_Problems) ) AS toFill_Bankruptcies,\n",
    "    BIGINT( PERCENTILE(Tax_Liens, 0.5) OVER(PARTITION BY Months_since_last_delinquent,\n",
    "                                            Number_of_Credit_Problems) ) AS toFill_Tax_Liens\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "sdf = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls(row):\n",
    "    d = row.asDict()\n",
    "    if d['Maximum_Open_Credit'] is None:\n",
    "        d['Maximum_Open_Credit'] = d['toFill_Maximum_Open_Credit']\n",
    "    if d['Bankruptcies'] is None:\n",
    "        d['Bankruptcies'] = d['toFill_Bankruptcies']\n",
    "    if d['Tax_Liens'] is None:\n",
    "        d['Tax_Liens'] = d['toFill_Tax_Liens']\n",
    "    return Row(**d)\n",
    "\n",
    "sdf = sdf.rdd.map(fill_nulls).toDF().select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Income:      14947\n",
      "Bankruptcies:          0\n",
      "Credit_Score:      14947\n",
      "Current_Credit_Balance:          0\n",
      "Current_Loan_Amount:          0\n",
      "Home_Ownership:          0\n",
      "Loan_Status:          0\n",
      "Maximum_Open_Credit:          0\n",
      "Monthly_Debt:          0\n",
      "Months_since_last_delinquent:          0\n",
      "Number_of_Credit_Problems:          0\n",
      "Number_of_Open_Accounts:          0\n",
      "Purpose:          0\n",
      "Tax_Liens:          0\n",
      "Term:          0\n",
      "Years_in_current_job:          0\n",
      "Years_of_Credit_History:          0\n"
     ]
    }
   ],
   "source": [
    "nbr_nulls = get_nbr_nulls(spark_df=sdf, view_name = 'Bank_Loan_Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filliamo i Missing Values degli attributi \"Credit_Score\" e \"Annual_Income\" dividendo il dataset in clusters e usando la Media dei valori nei clusters.\n",
    "\n",
    "Per effettuare il clustering dobbiamo considerare solo le colonne numeriche diverse da 'Credit_Score' e 'Annual_Income'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bankruptcies',\n",
       " 'Current_Credit_Balance',\n",
       " 'Current_Loan_Amount',\n",
       " 'Maximum_Open_Credit',\n",
       " 'Monthly_Debt',\n",
       " 'Number_of_Credit_Problems',\n",
       " 'Number_of_Open_Accounts',\n",
       " 'Tax_Liens',\n",
       " 'Years_in_current_job',\n",
       " 'Years_of_Credit_History']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_clustering = [col for col in columns_numerical if col != 'Credit_Score' and col != 'Annual_Income']\n",
    "\n",
    "columns_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = sdf.select(columns_clustering).rdd.map(lambda row: Vectors.dense(row))\n",
    "\n",
    "X_scaled = StandardScaler(withMean=True, withStd=True).fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migliora modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for k in range(1, 100):\\n    model = KMeans.train(X_scaled, k=10, maxIterations=20, initializationMode=\"random\")'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for k in range(1, 100):\n",
    "    model = KMeans.train(X_scaled, k=10, maxIterations=20, initializationMode=\"random\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KMeans.train(X_scaled, k=10, maxIterations=20, initializationMode=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def append_label(element):\n",
    "    d = element[0].asDict()\n",
    "    d['cluster_label'] = str(element[1])\n",
    "    return Row(**d)\n",
    "\n",
    "sdf = sdf.rdd.zip(model.predict(X_scaled)).map(append_label).toDF()\n",
    "\n",
    "columns = sdf.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT *,\n",
    "    BIGINT( PERCENTILE(Credit_Score, 0.5) OVER(PARTITION BY cluster_label) ) AS toFill_Credit_Score,\n",
    "    BIGINT( PERCENTILE(Annual_Income, 0.5) OVER(PARTITION BY cluster_label) ) AS toFill_Annual_Income\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "sdf = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Annual_Income: long (nullable = true)\n",
      " |-- Bankruptcies: long (nullable = true)\n",
      " |-- Credit_Score: long (nullable = true)\n",
      " |-- Current_Credit_Balance: long (nullable = true)\n",
      " |-- Current_Loan_Amount: long (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Maximum_Open_Credit: long (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Credit_Problems: long (nullable = true)\n",
      " |-- Number_of_Open_Accounts: long (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Tax_Liens: long (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Years_in_current_job: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      " |-- cluster_label: string (nullable = true)\n",
      " |-- toFill_Credit_Score: long (nullable = true)\n",
      " |-- toFill_Annual_Income: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------+----------------------+-------------------+--------------+-----------+-------------------+------------------+----------------------------+-------------------------+-----------------------+------------------+---------+----------+--------------------+-----------------------+-------------+-------------------+--------------------+\n",
      "|Annual_Income|Bankruptcies|Credit_Score|Current_Credit_Balance|Current_Loan_Amount|Home_Ownership|Loan_Status|Maximum_Open_Credit|      Monthly_Debt|Months_since_last_delinquent|Number_of_Credit_Problems|Number_of_Open_Accounts|           Purpose|Tax_Liens|      Term|Years_in_current_job|Years_of_Credit_History|cluster_label|toFill_Credit_Score|toFill_Annual_Income|\n",
      "+-------------+------------+------------+----------------------+-------------------+--------------+-----------+-------------------+------------------+----------------------------+-------------------------+-----------------------+------------------+---------+----------+--------------------+-----------------------+-------------+-------------------+--------------------+\n",
      "|        17298|           0|         713|                  1486|               1863| Home Mortgage| Fully Paid|               2827|298.40585714285714|                    [48, 96)|                        1|                     11|Debt Consolidation|        0|Short Term|                 5.0|                   12.6|            7|                726|               11914|\n",
      "+-------------+------------+------------+----------------------+-------------------+--------------+-----------+-------------------+------------------+----------------------------+-------------------------+-----------------------+------------------+---------+----------+--------------------+-----------------------+-------------+-------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_nulls(row):\n",
    "    d = row.asDict()\n",
    "    if d['Credit_Score'] is None:\n",
    "        d['Credit_Score'] = d['toFill_Credit_Score']\n",
    "    if d['Annual_Income'] is None:\n",
    "        d['Annual_Income'] = d['toFill_Annual_Income']\n",
    "    return Row(**d)\n",
    "\n",
    "sdf = sdf.rdd.map(fill_nulls).toDF().select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Annual_Income: long (nullable = true)\n",
      " |-- Bankruptcies: long (nullable = true)\n",
      " |-- Credit_Score: long (nullable = true)\n",
      " |-- Current_Credit_Balance: long (nullable = true)\n",
      " |-- Current_Loan_Amount: long (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Maximum_Open_Credit: long (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Credit_Problems: long (nullable = true)\n",
      " |-- Number_of_Open_Accounts: long (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Tax_Liens: long (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Years_in_current_job: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      " |-- cluster_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3f23a5731e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnbr_nulls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nbr_nulls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Bank_Loan_Dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-5a6303a9a432>\u001b[0m in \u001b[0;36mget_nbr_nulls\u001b[0;34m(spark_df, view_name, print_result)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\".format(Project, view_name)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnbr_nulls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \"\"\"\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \"\"\"\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nbr_nulls = get_nbr_nulls(spark_df=sdf, view_name = 'Bank_Loan_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il tasso cedolare infatti coincide con il tasso governativo decennale Russo del 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|nbr_rows|\n",
      "+--------+\n",
      "|   69057|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT COUNT(*) AS nbr_rows\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|Loan_Status|nbr_rows|\n",
      "+-----------+--------+\n",
      "| Fully Paid|   51088|\n",
      "|Charged Off|   17969|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT Loan_Status, COUNT(*) AS nbr_rows\n",
    "FROM Bank_Loan_Dataset\n",
    "GROUP BY Loan_Status \"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|Loan_Status| avg_Credit_Score|\n",
      "+-----------+-----------------+\n",
      "| Fully Paid|719.9645575699363|\n",
      "|Charged Off|710.2000954350247|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT Loan_Status, AVG(Credit_Score) AS avg_Credit_Score\n",
    "FROM Bank_Loan_Dataset\n",
    "GROUP BY Loan_Status \"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|Loan_Status|  avg_Credit_Score|\n",
      "+-----------+------------------+\n",
      "| Fully Paid|1410691.1453956058|\n",
      "|Charged Off|1253940.9389215843|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.createOrReplaceTempView('Bank_Loan_Dataset')\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT Loan_Status, AVG(Annual_Income) AS avg_Credit_Score\n",
    "FROM Bank_Loan_Dataset\n",
    "GROUP BY Loan_Status \"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = sdf.schema.names\n",
    "\n",
    "columns_categorical = [col.name for col in sdf.schema.fields if isinstance(col.dataType, StringType)]\n",
    "\n",
    "columns_numerical = [col for col in columns if col not in columns_categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.write.parquet(\"hdfs://kddrtserver11.isti.cnr.it:9000/user/hpsa04/bank_loan_status_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet(\"hdfs://kddrtserver11.isti.cnr.it:9000/user/hpsa04/bank_loan_status_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Loan_Status: string (nullable = true)\n",
      " |-- Current_Loan_Amount: long (nullable = true)\n",
      " |-- Term: string (nullable = true)\n",
      " |-- Credit_Score: double (nullable = true)\n",
      " |-- Annual_Income: double (nullable = true)\n",
      " |-- Years_in_current_job: string (nullable = true)\n",
      " |-- Home_Ownership: string (nullable = true)\n",
      " |-- Purpose: string (nullable = true)\n",
      " |-- Monthly_Debt: double (nullable = true)\n",
      " |-- Years_of_Credit_History: double (nullable = true)\n",
      " |-- Months_since_last_delinquent: string (nullable = true)\n",
      " |-- Number_of_Open_Accounts: string (nullable = true)\n",
      " |-- Number_of_Credit_Problems: string (nullable = true)\n",
      " |-- Current_Credit_Balance: long (nullable = true)\n",
      " |-- Maximum_Open_Credit: long (nullable = true)\n",
      " |-- Bankruptcies: string (nullable = true)\n",
      " |-- Tax_Liens: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ricordati!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anche se non esistono valori distinti  COUNT(\\*)  può differire da COUNT(DISTINCT \\*).\n",
    "\n",
    "perché il primo conta tutte le righe mentre il secondo conta tutte e sole le righe dove non è presente neanche un NULL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT COUNT(*) AS nbr_rows\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT COUNT(Credit_Score) AS nbr_rows\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT COUNT(DISTINCT *) AS nbr_rows\n",
    "FROM Bank_Loan_Dataset\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tentativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  tentativo non riuscito\\nrdd = sdf.rdd.map(lambda row: row.asDict())\\n\\nrdd.keyBy(lambda row: (row['Years_in_current_job'],\\n                             row['Home_Ownership'],\\n                             row['Number_of_Open_Accounts'],\\n                             row['Years_of_Credit_History'])).groupByKey()\\n                             \\ndef fill_null(d):\\n    if d['Maximum_Open_Credit'] == None:\\n        d['Maximum_Open_Credit'] = \\n    return d\\n\\nrdd.mapValues(fill_null)\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''  tentativo non riuscito per fillare i missing values\n",
    "rdd = sdf.rdd.map(lambda row: row.asDict())\n",
    "\n",
    "rdd.keyBy(lambda row: (row['Years_in_current_job'],\n",
    "                             row['Home_Ownership'],\n",
    "                             row['Number_of_Open_Accounts'],\n",
    "                             row['Years_of_Credit_History'])).groupByKey()\n",
    "                             \n",
    "def fill_null(d):\n",
    "    if d['Maximum_Open_Credit'] == None:\n",
    "        d['Maximum_Open_Credit'] = \n",
    "    return d\n",
    "\n",
    "rdd.mapValues(fill_null)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
